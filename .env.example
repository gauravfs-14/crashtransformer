# CrashTransformer Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Anthropic Claude Configuration  
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Google Gemini Configuration
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_MODEL=gemini-1.5-flash

# Groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile

# XAI Grok Configuration
XAI_API_KEY=your_xai_api_key_here
XAI_MODEL=grok-beta

# Ollama Configuration (Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# =============================================================================
# Database Configuration
# =============================================================================

# Neo4j Database
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# =============================================================================
# Cost and Pricing Configuration
# =============================================================================

# API Pricing (USD per 1k tokens)
OPENAI_INPUT_PRICE=0.0015
OPENAI_OUTPUT_PRICE=0.006
ANTHROPIC_INPUT_PRICE=0.003
ANTHROPIC_OUTPUT_PRICE=0.015
GOOGLE_INPUT_PRICE=0.0005
GOOGLE_OUTPUT_PRICE=0.0015
GROQ_INPUT_PRICE=0.0002
GROQ_OUTPUT_PRICE=0.0002

# Local GPU Pricing (USD per hour)
GPU_HOURLY_RATE=1.50

# =============================================================================
# Logging Configuration
# =============================================================================

# Log Directory
LOG_DIR=logs

# Log Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# Output Configuration
# =============================================================================

# Default Output Directory
OUTPUT_DIR=artifacts

# =============================================================================
# Model Configuration
# =============================================================================

# Default Summarization Model
DEFAULT_SUMMARIZATION_MODEL=facebook/bart-base

# =============================================================================
# Processing Configuration
# =============================================================================

# Cost Mode (local, api)
COST_MODE=local

# Batch Processing
BATCH_SIZE=100
MAX_WORKERS=4

# =============================================================================
# Security Configuration
# =============================================================================

# Enable/Disable features
ENABLE_NEO4J=false
ENABLE_LOGGING=true
ENABLE_COST_TRACKING=true

# =============================================================================
# Example Usage
# =============================================================================

# To use this configuration:
# 1. Copy this file to .env
# 2. Fill in your actual API keys and configuration
# 3. Run: python main_pipeline.py --csv crashes.csv
#
# The pipeline will automatically use the environment variables
# for sensitive configuration while still allowing CLI overrides
# for non-sensitive options like model selection and output paths.
