# ğŸ”§ CrashTransformer - AI-Powered Crash Analysis Pipeline

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Neo4j](https://img.shields.io/badge/Neo4j-6.0+-green.svg)](https://neo4j.com/)

CrashTransformer is a sophisticated AI system that processes vehicle crash narratives into structured causal summaries using Large Language Models and transformer-based summarization. It extracts structured crash graphs, generates high-quality summaries, and provides comprehensive analytics through multiple LLM providers and graph database integration.

## âœ¨ Key Features

- **ğŸ¤– Multi-Provider LLM Support**: OpenAI, Anthropic, Google, Groq, Ollama, XAI
- **ğŸ“Š Advanced Analytics**: Graph extraction, dual summarization, quality metrics
- **ğŸ—„ï¸ Graph Database Integration**: Neo4j support for complex pattern analysis
- **ğŸ’° Cost Tracking**: Real-time token usage and cost optimization
- **ğŸ”§ Flexible Configuration**: Environment-based setup with CLI overrides

## ğŸš€ Quick Start

```bash
# 1. Setup environment (first time only)
python crashtransformer.py setup

# 2. Run the pipeline
python crashtransformer.py run --csv crashes.csv
```

## ğŸ“‹ Main Commands

| Command | Description | Example |
|---------|-------------|---------|
| `setup` | Interactive environment configuration | `python crashtransformer.py setup` |
| `run` | Execute crash analysis pipeline | `python crashtransformer.py run --csv crashes.csv` |
| `train` | Fine-tune summarization models | `python crashtransformer.py train --training_data data.csv` |
| `prepare-data` | Prepare training data from outputs | `python crashtransformer.py prepare-data --source pipeline` |
| `clean-db` | Clear Neo4j database | `python crashtransformer.py clean-db` |
| `docs` | Open local HTML documentation | `python crashtransformer.py docs` |
| `help` | Show comprehensive help | `python crashtransformer.py help` |

## ğŸ¯ Core Features

### **ğŸ¤– Multi-Provider LLM Support**

| Provider | Models | Speed | Cost | Quality | Best For |
|----------|--------|-------|------|---------|----------|
| **OpenAI** | GPT-4o, GPT-4o-mini, GPT-3.5-turbo | â­â­â­ | â­â­â­ | â­â­â­â­ | Balanced performance |
| **Anthropic** | Claude-3 Opus, Sonnet, Haiku | â­â­ | â­â­ | â­â­â­â­â­ | High-quality analysis |
| **Google** | Gemini-2.0-Flash, Gemini-1.5-Pro | â­â­â­ | â­â­â­â­ | â­â­â­â­ | Cost-effective processing |
| **Groq** | Llama-3.1-70b, Mixtral-8x7b | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | Fast inference |
| **Ollama** | Local models (Llama3, Mistral) | â­â­â­â­ | â­â­â­â­â­ | â­â­ | Privacy-focused |
| **XAI** | Grok-Beta, Grok-2 | â­â­â­ | â­â­â­ | â­â­â­â­ | Latest models |

### **ğŸ“Š Advanced Analytics**

- **ğŸ§  Graph Extraction**: LLM-powered structured entities, events, and causal relationships
- **ğŸ“ Dual Summarization**: Both LLM and fine-tuned model summaries for comprehensive analysis
- **âš¡ Single LLM Call**: Efficient API usage - one call generates both graph and summary
- **ğŸ“ˆ Quality Metrics**: Precision, recall, faithfulness, hallucination rates, ROUGE, BLEU, BERTScore
- **ğŸ’° Cost Tracking**: Real-time token usage, runtime, and monetary costs for all providers
- **ğŸ“Š Performance Analytics**: Processing times, throughput analysis, and model comparison

### **ğŸ—„ï¸ Data Storage & Integration**

- **ğŸ“ File Outputs**: JSON, JSONL, CSV formats with structured data
- **ğŸ•¸ï¸ Graph Database**: Neo4j integration for complex pattern analysis and queries
- **ğŸ“ Comprehensive Logging**: Timestamped, structured logs with detailed processing information
- **ğŸ’µ Cost Reports**: Detailed financial analysis and optimization recommendations

## ğŸ”§ Environment Setup

### **Interactive Setup (Recommended)**

```bash
# Guided setup process
python crashtransformer.py setup

# Direct interactive setup
python crashtransformer.py setup --interactive
```

### **Manual Setup**

```bash
# Create .env from template
python crashtransformer.py setup --create-env

# Validate configuration
python crashtransformer.py validate

# Install dependencies
python crashtransformer.py install
```

## ğŸš€ Pipeline Execution

### **Basic Usage**

```bash
# Use environment configuration
python crashtransformer.py run --csv crashes.csv

# Override LLM provider
python crashtransformer.py run --csv crashes.csv --llm_provider anthropic

# Enable Neo4j storage
python crashtransformer.py run --csv crashes.csv --neo4j_enabled

# Debug mode
python crashtransformer.py run --csv crashes.csv --log_level DEBUG
```

### **Advanced Usage**

```bash
# Multiple summarization models
python crashtransformer.py run --csv crashes.csv --batch_models facebook/bart-base t5-base

# Custom output directory
python crashtransformer.py run --csv crashes.csv --out_dir results

# Cost tracking mode
python crashtransformer.py run --csv crashes.csv --cost_mode api
```

## ğŸ“Š Input Requirements

### **CSV/XLSX Format**

| Column | Type | Required | Description |
|--------|------|----------|-------------|
| `Crash_ID` | String | âœ… | Unique crash identifier |
| `Latitude` | Float | âœ… | Geographic latitude coordinate |
| `Longitude` | Float | âœ… | Geographic longitude coordinate |
| `CrashDate` | String | âœ… | Date of crash (YYYY-MM-DD format) |
| `DayOfWeek` | String | âœ… | Day of week (MON, TUE, etc.) |
| `CrashTime` | String | âœ… | Time of crash (HH:MM format) |
| `County` | String | âœ… | County name |
| `City` | String | âœ… | City name |
| `SAE_Autonomy_Level` | String | âœ… | Vehicle autonomy level (0-5) |
| `Crash_Severity` | String | âœ… | Severity classification |
| `Narrative` | String | âœ… | Crash description text |

### **Example Input**

```csv
Crash_ID,Latitude,Longitude,CrashDate,DayOfWeek,CrashTime,County,City,SAE_Autonomy_Level,Crash_Severity,Narrative
19955047,26.15526348,-97.99060556,2023-01-15,Sunday,14:30,Hidalgo,Weslaco,Level 0,Not Injured,"Unit 2 was stationary in the northbound lane. Unit 1 failed to control speed and struck Unit 2 on the back end."
19955369,32.92553538,-96.80385791,2023-01-16,Monday,15:37,Dallas,Dallas,Level 1,Injured,"Unit 1 was traveling eastbound on Main Street. Unit 2 was traveling northbound on Oak Avenue. Unit 1 failed to yield at the stop sign and collided with Unit 2 at the intersection."
```

## ğŸ“ˆ Outputs Generated

### **1. Structured Graph Data**

The system extracts structured crash graphs with entities, events, and causal relationships:

```json
{
  "crash": {
    "crash_id": "19955047",
    "latitude": 26.15526348,
    "longitude": -97.99060556,
    "city": "Weslaco",
    "crash_severity": "Not Injured",
    "raw_narrative": "Unit 2 was stationary in the northbound lane. Unit 1 failed to control speed and struck Unit 2 on the back end."
  },
  "entities": [
    {"id": "19955047:U1", "label": "VEHICLE", "unit_id": "1", "name": "Unit 1"},
    {"id": "19955047:U2", "label": "VEHICLE", "unit_id": "2", "name": "Unit 2"},
    {"id": "19955047:L1", "label": "ROAD", "name": "S. Texas Blvd", "city": "Weslaco"}
  ],
  "events": [
    {"id": "19955047:E1", "type": "VIOLATION", "label": "Failure to Control Speed", "evidence_span": "Unit 1 failed to control speed"},
    {"id": "19955047:E2", "type": "COLLISION", "label": "Rear-End Collision", "evidence_span": "struck Unit 2 on the back end"}
  ],
  "relationships": [
    {"start": "19955047:U1", "end": "19955047:E1", "type": "PARTICIPATED_IN", "properties": {"role": "agent"}},
    {"start": "19955047:E1", "end": "19955047:E2", "type": "CAUSES", "properties": {"marked": true, "connective": "failed to control speed"}},
    {"start": "19955047:U1", "end": "19955047:U2", "type": "HIT", "properties": {"impact_config": "rear_end"}}
  ]
}
```

### **2. Causal Summaries**

High-quality summaries with comprehensive quality metrics:

```text
Input: "Unit 2 was stationary in the northbound lane. Unit 1 failed to control speed and struck Unit 2 on the back end."

Output: "Unit 1 failed to control speed and struck the stationary Unit 2 from behind, causing a rear-end collision."

Quality Metrics: {
  "causal_precision": 0.95,
  "causal_recall": 0.90,
  "causal_f1": 0.92,
  "span_faithfulness": 0.88,
  "hallucination_rate": 0.05,
  "compression_ratio": 0.15,
  "combined_score": 0.89,
  "rouge_rouge1_f1": 0.87,
  "bertscore_f1": 0.91
}
```

### **3. File Outputs**

| File | Description | Format |
|------|-------------|--------|
| `crash_graphs.jsonl` | Structured graph data | JSONL |
| `crash_summaries.jsonl` | Generated summaries with metrics | JSONL |
| `summaries_metrics.csv` | Quality metrics and performance data | CSV |
| `cost_report.json` | Cost analysis and optimization | JSON |
| `logs/crashtransformer-*.log` | Processing logs | Text |

### **4. Neo4j Graph Database**

Advanced graph database integration for complex pattern analysis:

- **Nodes**: `Crash`, `Vehicle`, `Location`, `Event`, `Summary`
- **Relationships**: `HAS_ENTITY`, `HAS_EVENT`, `CAUSES`, `PARTICIPATED_IN`, `HIT`, `HAS_SUMMARY`

See [NEO4J_GUIDE.md](docs/NEO4J_GUIDE.md) for comprehensive Cypher queries and analytics.

## ğŸ”’ Security & Configuration

### **Environment Variables**

All sensitive configuration is managed through `.env` file:

```bash
# LLM Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini

# Database Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-secure-password
ENABLE_NEO4J=false

# Logging Configuration
LOG_DIR=logs
LOG_LEVEL=INFO
ENABLE_LOGGING=true
```

### **Security Features**

- **ğŸ” Hidden Input**: API keys never displayed in terminal
- **ğŸ” Secure Storage**: Configuration saved to `.env` file
- **ğŸ” Validation**: Automatic configuration checking
- **ğŸ” No CLI Secrets**: Sensitive data only via environment variables

## ğŸ“Š Performance & Cost Optimization

### **Provider Selection Guide**

| Provider | Speed | Cost | Quality | Use Case |
|----------|-------|------|---------|----------|
| **Groq** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | Fast processing |
| **OpenAI** | â­â­â­ | â­â­â­ | â­â­â­â­ | Balanced |
| **Anthropic** | â­â­ | â­â­ | â­â­â­â­â­ | High quality |
| **Google** | â­â­â­ | â­â­â­â­ | â­â­â­â­ | Cost-effective |
| **Ollama** | â­â­â­â­ | â­â­â­â­â­ | â­â­ | Local processing |

### **Cost Tracking**

- **Token Usage**: Input/output tokens for each stage
- **API Costs**: Real-time cost calculation
- **GPU Costs**: Local processing costs
- **Optimization**: Cost per 1,000 summaries analysis

## ğŸ› ï¸ Development & Customization

### **Project Structure**

```text
crashtransformer/
â”œâ”€â”€ crashtransformer.py              # Main entry point
â”œâ”€â”€ src/                             # Source code
â”‚   â”œâ”€â”€ main_pipeline.py             # Pipeline orchestration
â”‚   â”œâ”€â”€ setup_env.py                # Environment setup
â”‚   â”œâ”€â”€ prepare_training_data.py    # Training data preparation
â”‚   â”œâ”€â”€ train_model.py              # Model fine-tuning
â”‚   â””â”€â”€ utils/                       # Core modules
â”‚       â”œâ”€â”€ crash_graph_llm.py      # LLM integration & structured output
â”‚       â”œâ”€â”€ causal_plan_summarizer.py # Summarization & quality metrics
â”‚       â”œâ”€â”€ cost_tracker.py         # Cost tracking & optimization
â”‚       â”œâ”€â”€ neo4j_io.py             # Graph database integration
â”‚       â”œâ”€â”€ llm_providers.py        # Multi-provider support
â”‚       â”œâ”€â”€ advanced_metrics.py     # NLP quality metrics
â”‚       â”œâ”€â”€ fine_tuning.py          # Model fine-tuning utilities
â”‚       â””â”€â”€ config.py               # Configuration management
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ NEO4J_GUIDE.md              # Neo4j integration guide
â”‚   â”œâ”€â”€ USAGE_GUIDE.md              # Usage documentation
â”‚   â””â”€â”€ ...                         # Additional guides
â”œâ”€â”€ data/                           # Sample data
â”œâ”€â”€ logs/                           # Processing logs
â””â”€â”€ artifacts/                      # Output directory
```

### **Key Components**

| Component | Description | Key Features |
|-----------|-------------|---------------|
| **crash_graph_llm.py** | LLM integration | Structured output, multi-provider support |
| **causal_plan_summarizer.py** | Summarization | Quality metrics, BART/T5 models |
| **neo4j_io.py** | Graph database | CRUD operations, constraints, indexes |
| **llm_providers.py** | Provider abstraction | OpenAI, Anthropic, Google, Groq, Ollama, XAI |
| **cost_tracker.py** | Cost management | Token tracking, cost optimization |
| **advanced_metrics.py** | Quality assessment | ROUGE, BLEU, BERTScore, semantic similarity |

### **Customization Options**

- **ğŸ”§ Custom Models**: Add new LLM providers via `LLMProviderFactory`
- **ğŸ“Š Custom Metrics**: Extend quality scoring in `advanced_metrics.py`
- **ğŸ“ Custom Outputs**: Add new output formats in `main_pipeline.py`
- **âš™ï¸ Custom Processing**: Extend pipeline stages with new modules
- **ğŸ¯ Fine-tuning**: Custom model training with `train_model.py`

## ğŸ› Troubleshooting

### **Common Issues**

1. **Import Errors**

   ```bash
   âŒ Error importing setup module
   ```

   **Solution**: Ensure you're in the correct directory with `src/` folder

2. **Configuration Errors**

   ```bash
   âŒ Configuration validation failed
   ```

   **Solution**: Run `python crashtransformer.py setup` to configure

3. **API Key Issues**

   ```bash
   âŒ OPENAI_API_KEY not set
   ```

   **Solution**: Run interactive setup and enter valid API key

### **Debug Mode**

```bash
# Enable debug logging
python crashtransformer.py run --csv crashes.csv --log_level DEBUG

# Check configuration
python crashtransformer.py validate
```

## ğŸ“š Documentation

| Document | Description | Purpose |
|----------|-------------|---------|
| **[NEO4J_GUIDE.md](docs/NEO4J_GUIDE.md)** | Neo4j integration & Cypher queries | Graph database analytics |
| **[USAGE_GUIDE.md](docs/USAGE_GUIDE.md)** | Complete usage documentation | Getting started guide |
| **[ENVIRONMENT_SETUP.md](docs/ENVIRONMENT_SETUP.md)** | Configuration setup | Environment configuration |
| **[PROVIDERS_GUIDE.md](docs/PROVIDERS_GUIDE.md)** | LLM provider comparison | Provider selection |
| **[COST_PERFORMANCE.md](docs/COST_PERFORMANCE.md)** | Cost optimization guide | Performance tuning |
| **[FINE_TUNING_GUIDE.md](docs/FINE_TUNING_GUIDE.md)** | Model fine-tuning | Custom model training |

## ğŸ¯ Use Cases

| Industry | Use Case | Benefits |
|----------|----------|----------|
| **ğŸ¢ Insurance** | Automated crash report analysis | Faster claims processing, fraud detection |
| **ğŸš— Transportation** | Safety pattern analysis | Accident prevention, infrastructure planning |
| **âš–ï¸ Legal** | Evidence extraction and summarization | Case preparation, documentation |
| **ğŸ”¬ Research** | Large-scale crash data analysis | Statistical insights, trend analysis |
| **ğŸ“‹ Compliance** | Regulatory reporting | Automated documentation, audit trails |

## ğŸš€ Getting Started

### **Quick Setup**

```bash
# 1. Clone the repository
git clone https://github.com/your-org/crashtransformer.git
cd crashtransformer

# 2. Setup environment
python crashtransformer.py setup

# 3. Prepare your data (ensure CSV has required columns)
# 4. Run the pipeline
python crashtransformer.py run --csv crashes.csv

# 5. Check results in artifacts/ directory
```

### **Advanced Setup**

```bash
# Enable Neo4j for graph analytics
python crashtransformer.py run --csv crashes.csv --neo4j_enabled

# Use specific LLM provider
python crashtransformer.py run --csv crashes.csv --llm_provider anthropic

# Compare multiple models
python crashtransformer.py run --csv crashes.csv --batch_models facebook/bart-base t5-base
```

## ğŸ“ Support & Community

### **Getting Help**

- ğŸ“– **Documentation**: Check `docs/` folder for comprehensive guides
- ğŸ†˜ **CLI Help**: Run `python crashtransformer.py help`
- ğŸ“ **Logs**: Review processing logs in `logs/` directory
- ğŸ› **Issues**: Report bugs and feature requests on GitHub

### **Contributing**

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## CrashTransformer

Transforming crash narratives into actionable insights with AI! ğŸš—ğŸ’¥ğŸ¤–
